{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5: 'Based on the following definitions of fallacies,\\n1. Ad Hominem is a fallacy when someone attacks the others\\' characters or motives instead of addressing the substance of their arguments.\\n2. Appeal to Opinions of False Authority is a fallacy when someone attempts to argue or persuade by referring to the opinions or statements of another questionable authority figure who lacks sufficient credibility in the discussed matter because the authority\\'s expertise may be inadequate/irrelevant or the authority is attributed a statement that has been tweaked.\\n3. Red Herring is a fallacy when someone introduces irrelevant or confusing information in arguments to diverge attention from the main topic being discussed to irrelevant issues.\\n4. Appeal to Emotion is a fallacy when someone attempts to argue or persuade by using emotive language to arouse non-rational sentiments within the intended audience.\\n5. Hasty Generalization is a fallacy when someone makes generalizations based on partial/incomplete observations on a small sample of the whole populations that cannot represent or generalize to other situations legitimately.\\nGiven the conversation below,\\nA: Is it justified to develop nuclear energy for commercial use?\\nB: The green party in Germany has the opinion, that nuclear reactors are bad for us. It is not ok\\nDetermine whether any of the fallacies defined above is present in B\\'s argument replied to A?\\nOutput your answer in JSON format {\"fallacy\": name_of_the_fallacy, \"explanation\": in_a_sentence_or_two}. If none of the fallacies is found, output {\"fallacy\": \"No Fallacy\", \"explanation\": in_a_sentence_or_two}. Only output JSON.\\n', 0: 'According to the definition of Ad Hominem: \"a fallacy when someone attacks the others\\' characters or motives instead of addressing the substance of their arguments.\", given the conversation below: \\nA: Is it justified to develop nuclear energy for commercial use?\\nB: The green party in Germany has the opinion, that nuclear reactors are bad for us. It is not ok\\n, is the fallacy defined above present or absent in B\\'s argument?', 1: 'According to the definition of Appeal to Opinions of False Authority: \"a fallacy when someone attempts to argue or persuade by referring to the opinions or statements of another questionable authority figure who lacks sufficient credibility in the discussed matter because the authority\\'s expertise may be inadequate/irrelevant or the authority is attributed a statement that has been tweaked.\", given the conversation below: \\nA: Is it justified to develop nuclear energy for commercial use?\\nB: The green party in Germany has the opinion, that nuclear reactors are bad for us. It is not ok\\n, is the fallacy defined above present or absent in B\\'s argument?', 2: 'According to the definition of Red Herring: \"a fallacy when someone introduces irrelevant or confusing information in arguments to diverge attention from the main topic being discussed to irrelevant issues.\", given the conversation below: \\nA: Is it justified to develop nuclear energy for commercial use?\\nB: The green party in Germany has the opinion, that nuclear reactors are bad for us. It is not ok\\n, is the fallacy defined above present or absent in B\\'s argument?', 3: 'According to the definition of Appeal to Emotion: \"a fallacy when someone attempts to argue or persuade by using emotive language to arouse non-rational sentiments within the intended audience.\", given the conversation below: \\nA: Is it justified to develop nuclear energy for commercial use?\\nB: The green party in Germany has the opinion, that nuclear reactors are bad for us. It is not ok\\n, is the fallacy defined above present or absent in B\\'s argument?', 4: 'According to the definition of Hasty Generalization: \"a fallacy when someone makes generalizations based on partial/incomplete observations on a small sample of the whole populations that cannot represent or generalize to other situations legitimately.\", given the conversation below: \\nA: Is it justified to develop nuclear energy for commercial use?\\nB: The green party in Germany has the opinion, that nuclear reactors are bad for us. It is not ok\\n, is the fallacy defined above present or absent in B\\'s argument?'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"2\"\n",
    "import torch\n",
    "from transformers import (\n",
    "    LlamaConfig, LlamaForCausalLM, LlamaTokenizer\n",
    ")\n",
    "from utils.fallacy_utils import *\n",
    "from utils.format_utils import format_tokens\n",
    "import pprint\n",
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "argo_fal = [\n",
    "'Appeal to Emotion',\n",
    "'Red Herring',\n",
    "'Hasty Generalization',\n",
    "'Ad Hominem',\n",
    "'Appeal to False Authority'\n",
    "]\n",
    "\n",
    "FALLACY_DEFINITIONS = {\n",
    "\"Ad Hominem\": \"a fallacy when someone attacks the others' characters or motives instead of addressing the substance of their arguments.\",\n",
    "\"Appeal to Opinions of False Authority\": \"a fallacy when someone attempts to argue or persuade by referring to the opinions or statements of another questionable authority figure who lacks sufficient credibility in the discussed matter because the authority's expertise may be inadequate/irrelevant or the authority is attributed a statement that has been tweaked.\",\n",
    "\"Red Herring\": \"a fallacy when someone introduces irrelevant or confusing information in arguments to diverge attention from the main topic being discussed to irrelevant issues.\",\n",
    "\"Appeal to Emotion\": \"a fallacy when someone attempts to argue or persuade by using emotive language to arouse non-rational sentiments within the intended audience.\",\n",
    "\"Hasty Generalization\": \"a fallacy when someone makes generalizations based on partial/incomplete observations on a small sample of the whole populations that cannot represent or generalize to other situations legitimately.\"\n",
    "}\n",
    "argo_fal = list(FALLACY_DEFINITIONS.keys())\n",
    "BASELINE_TEMPLATES =[\n",
    "'''Review the definitions of these fallacies,\n",
    "{definitions}\n",
    "Review the conversation,\n",
    "{dialog}\n",
    "Based on all your previous analysis, determine which of the fallacies defined above is most dominantly present in B's argument replied to A?\n",
    "Output your answer in JSON format {{\"fallacy\": name_of_the_fallacy, \"explanation\": in_a_sentence_or_two}}. If none of the fallacies is found, output {{\"fallacy\": \"No Fallacy\", \"explanation\": in_a_sentence_or_two}}. Only output JSON.\n",
    "''',\n",
    "'''Based on the following definitions of fallacies,\n",
    "{definitions}\n",
    "Given the conversation below,\n",
    "{dialog}\n",
    "Determine whether any of the fallacies defined above is present in B's argument replied to A?\n",
    "Output your answer in JSON format {{\"fallacy\": name_of_the_fallacy, \"explanation\": in_a_sentence_or_two}}. If none of the fallacies is found, output {{\"fallacy\": \"No Fallacy\", \"explanation\": in_a_sentence_or_two}}. Only output JSON.\n",
    "'''\n",
    "]\n",
    "#about Hasty Generalization, Appeal to Emotion, Ad Hominem, Red Herring and Appeal to False Authority\n",
    "def get_USER_PROMPTS(qa):\n",
    "    #ASK_SINGLE_FALLACY = \"\"\"According to the definition of {name}: \"{defi}\", considering B's stance, determine whether this fallacy is present or absent in B's argument.\"\"\"\n",
    "    #ASK_SINGLE_FALLACY = \"\"\"According to the definition of {name}: \"{defi}\", review the conversation again \"{dialog}\", is this fallacy present in B's argument?\"\"\"\n",
    "    ASK_SINGLE_FALLACY = \"\"\"According to the definition of {name}: \"{defi}\", given the conversation below: \\n{dialog}\\n, is the fallacy defined above present or absent in B's argument?\"\"\"\n",
    "    def_str = \"\\n\".join([f\"{str(i+1)}. {fal} is {FALLACY_DEFINITIONS[fal]}\" for i, fal in enumerate(argo_fal)]) \n",
    "    USER_PROMPTS = {\n",
    "    #0:\"\"\"Given the conversation below,\\n{dialog}\\nIs B in favor of or against the topic proposed by A?\"\"\".format(dialog=qa),\n",
    "    #5:\"\"\"Based on all your previous analysis, output all the fallacy/fallacies present in B's argument in JSON format {{\"fallacy\": [name(s)_of_the_fallacy]}}. If none of the fallacies is present, output {{\"fallacy\": \"No Fallacy\"}}. Only output JSON.\"\"\"\n",
    "    #5:\"\"\"Based on all your previous analysis, determine which of the fallacies defined above is dominantly present in B's argument replied to A? Output the fallacy in JSON format {{\"fallacy\": name_of_the_fallacy}}. If none of the fallacies is present, output {{\"fallacy\": \"No Fallacy\"}}. Only output JSON.\"\"\"\n",
    "    5: BASELINE_TEMPLATES[1].format(definitions=def_str, dialog=qa)\n",
    "    }#1:\"\"\"Considering B's stance, is it logically sound for B to draw an argument like that?\"\"\",\n",
    "    def_questions = {}\n",
    "    for i, (name, def_) in enumerate(FALLACY_DEFINITIONS.items()):\n",
    "        def_questions[i] = ASK_SINGLE_FALLACY.format(name=name, defi=def_, dialog=qa)\n",
    "    USER_PROMPTS.update(def_questions)\n",
    "    return USER_PROMPTS\n",
    "\n",
    "# Test examples\n",
    "qa0=\"A: Is democracy the best system available?\\nB: good point. why not\" # no fallacy??\n",
    "qa1=\"A: Is veganism the best for our bodies?\\nB: humans are omnivores, we need both meat and vegetables.\" #ad homien??\n",
    "qa2=\"A: Has anyone been on the moon?\\nB: The moon is so far away, we should focus on our society.\" # red hering\n",
    "qa3 = \"A: Is global warming really an issue?\\nB: Yes, all the polar-bears are dying, and we are next.\"\n",
    "qa4 = \"A: Is there a good reason for the American war on terror?\\nB: If you fight once you will never stop fighting. Never start!\"\n",
    "qa5 = \"A: Is it justified to develop nuclear energy for commercial use?\\nB: The green party in Germany has the opinion, that nuclear reactors are bad for us. It is not ok\" # false authority\n",
    "qa6 = '''A: Should smoking at home be illegal?\\nB: Home is the place of love and peace, how can you fog it with smoke?'''#appeal to emotion\n",
    "qa7 = \"A: Do we need a global environment task force?\\nB: It is people like you who force us normal people into the dictatorship of unnecessary organizations.\" #ad hominem\n",
    "qa8 = \"A: Is it effective to censor parts of the media?\\nB: It is effective to censor parts of the media, because you never know who is watching.\"\n",
    "qa9 = \"A: Do we need a global environment task force?\\nB: The global taskforce for human rights is doing a good job. Thats why we need one for environment,  too.\"\n",
    "qa10 = \"A: Do we need a global environment task force?\\nB: Yes, we need. There're some important enviroment issues that need global efforts to address.\"\n",
    "qa11 = \"A: Should animals have special rights?\\nB: Regarding this argumentation you have the IQ of an insect. Do you think you need special rights?\" #ad hominem\n",
    "qa_emotion = \"A: Is nuclear power a reasonable energy source?\\nB: Nuclear power was the reason of death of millions of people. It should vanish from this planet.\"\n",
    "\n",
    "prompts = get_USER_PROMPTS(qa5)\n",
    "print(prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "361edaaac6c5473d829f1dfeae964d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = './models/llama2_hf/13bf'\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_id)\n",
    "kwargs = {'load_in_8bit': True, 'torch_dtype':torch.float16, 'low_cpu_mem_usage':True}#'device_map':'auto', \n",
    "model = LlamaForCausalLM.from_pretrained(model_id, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 518, 25580, 29962]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(E_INST)\n",
    "tokenizer.encode(B_INST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    \"max_new_tokens\": 512,\n",
    "    \"do_sample\" : True,\n",
    "    \"top_p\": 0.9,#0.9, 0.5\n",
    "    \"temperature\": 0.75,#0.75, 0.5\n",
    "    \"use_cache\": True,\n",
    "    \"top_k\" : 50,#50,30\n",
    "    \"repetition_penalty\": 1.,\n",
    "    \"length_penalty\": 1\n",
    "}\n",
    "def MultiturnChat(tokenizer, model, prompt, chat_history):\n",
    "    #print(chat_history)\n",
    "    def format_prompt(prompt, chat_history):\n",
    "        SYSTEM_PROMPT = [\n",
    "            '''You are a knowledgable expert in detecting fallacies in arguments. \n",
    "            Please ensure that your responses are socially unbiased and positive in nature.\n",
    "            If you don't know the answer to a question, please don't share false information.\n",
    "            Answer the last question.''',\n",
    "            '''You are a knowledgable expert in analysing fallacies in arguments. \n",
    "            Please ensure that your responses are socially unbiased in nature.\n",
    "            Your response should not be lengthy.\n",
    "            Answer the last question.'''\n",
    "        ]\n",
    "        dialog = []\n",
    "        sys_pt = {\"role\": \"system\", \"content\": SYSTEM_PROMPT[1]}\n",
    "        usr_pt = {\"role\": \"user\", \"content\": prompt}\n",
    "        if chat_history:\n",
    "            dialog = [sys_pt] + chat_history + [usr_pt]\n",
    "        else:\n",
    "            dialog = [sys_pt] + [usr_pt]\n",
    "        chat_history = dialog\n",
    "        #print(chat_history)        \n",
    "        #formatted_prompt = format_tokens(None, [dialog], tokenizer)[0]\n",
    "        if dialog[0][\"role\"] == \"system\":\n",
    "            dialog = [\n",
    "            {\n",
    "                \"role\": dialog[1][\"role\"],\n",
    "                \"content\": B_SYS\n",
    "                + dialog[0][\"content\"]\n",
    "                + E_SYS\n",
    "                + dialog[1][\"content\"],\n",
    "            }\n",
    "            ] + dialog[2:]\n",
    "        assert all([msg[\"role\"] == \"user\" for msg in dialog[::2]]) and all([msg[\"role\"] == \"assistant\" for msg in dialog[1::2]]), (\n",
    "            \"model only supports 'system','user' and 'assistant' roles, \"\n",
    "            \"starting with user and alternating (u/a/u/a/u...)\")\n",
    "        \"\"\"\n",
    "        Please verify that your tokenizer support adding \"[INST]\", \"[/INST]\" to your inputs.\n",
    "        Here, we are adding it manually.\n",
    "        \"\"\"\n",
    "        formatted_dialog = [\n",
    "            f\"{B_INST} {(prompt['content']).strip()} {E_INST} {(answer['content']).strip()} \"\n",
    "            for prompt, answer in zip(dialog[::2], dialog[1::2])\n",
    "        ]\n",
    "        \n",
    "        assert (\n",
    "            dialog[-1][\"role\"] == \"user\"\n",
    "        ), f\"Last message must be from user, got {dialog[-1]['role']}\"\n",
    "        formatted_dialog += [f\"{B_INST} {(dialog[-1]['content']).strip()} {E_INST}\"]\n",
    "            \n",
    "        return \"\".join(formatted_dialog), chat_history\n",
    "    \n",
    "    formatted_prompt, chat_history = format_prompt(prompt, chat_history)\n",
    "    model_input = tokenizer(formatted_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    print(model_input.input_ids)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        response = tokenizer.decode(model.generate(**model_input, **kwargs)[0], skip_special_tokens=True)\n",
    "        res = response.split(E_INST)\n",
    "        print(\"\\n\".join(res[:-1]))\n",
    "        print()\n",
    "        print(pprint.pformat(res[-1]))\n",
    "        chat_history = chat_history[1:] + [{\"role\":\"assistant\", \"content\":res[-1]}]\n",
    "        return chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,   518, 25580, 29962,  3532, 14816, 29903,  6778,    13,  3492,\n",
      "           526,   263,  1073,   839, 29531, 17924,   297,  3483,   952,   292,\n",
      "           285,  9864,  2478,   297,  6273, 29889, 29871,    13,  9651,  3529,\n",
      "          9801,   393,   596, 20890,   526,  5374,   635,   443,  5365,  1463,\n",
      "           297,  5469, 29889,    13,  9651,  3575,  2933,   881,   451,   367,\n",
      "          3309, 29891, 29889,    13,  9651,   673,   278,  1833,  1139, 29889,\n",
      "            13, 29966,   829, 14816, 29903,  6778,    13,    13,  7504,  3278,\n",
      "           304,   278,  5023,   310,  2087,   379,  5817,   331, 29901,   376,\n",
      "         29874,   285,  9864,  1270,   746,  4856, 16661,   278,  4045, 29915,\n",
      "          4890,   470,  3184,  3145,  2012,   310,  3211,   292,   278,  5960,\n",
      "           749,   310,  1009,  6273, 19602,  2183,   278, 14983,  2400, 29901,\n",
      "         29871,    13, 29909, 29901,  1317,   372,   925,  2164,   304,  2693,\n",
      "         20346,  5864,   363, 12128,   671, 29973,    13, 29933, 29901,   450,\n",
      "          7933,  6263,   297,  9556,   756,   278,  9426, 29892,   393, 20346,\n",
      "          7657,   943,   526,  4319,   363,   502, 29889,   739,   338,   451,\n",
      "          3431,    13, 29892,   338,   278,   285,  9864,  1270,  3342,  2038,\n",
      "          2198,   470, 29207,   297,   350, 29915, 29879,  2980, 29973,   518,\n",
      "         29914, 25580, 29962]], device='cuda:0')\n",
      "[INST] <<SYS>>\n",
      "You are a knowledgable expert in analysing fallacies in arguments. \n",
      "            Please ensure that your responses are socially unbiased in nature.\n",
      "            Your response should not be lengthy.\n",
      "            Answer the last question.\n",
      "<</SYS>>\n",
      "\n",
      "According to the definition of Ad Hominem: \"a fallacy when someone attacks the others' characters or motives instead of addressing the substance of their arguments.\", given the conversation below: \n",
      "A: Is it justified to develop nuclear energy for commercial use?\n",
      "B: The green party in Germany has the opinion, that nuclear reactors are bad for us. It is not ok\n",
      ", is the fallacy defined above present or absent in B's argument? \n",
      "\n",
      "(\"  The fallacy of Ad Hominem is not present in B's argument. B is not \"\n",
      " 'attacking the character or motives of the Green Party in Germany, but rather '\n",
      " 'stating their opinion on the matter. The argument focuses on the substance '\n",
      " 'of the issue, rather than attacking the person or group holding the opinion. '\n",
      " \"Therefore, the Ad Hominem fallacy is not present in B's argument.\")\n"
     ]
    }
   ],
   "source": [
    "chat_history = MultiturnChat(tokenizer, model, prompts[0], chat_history=chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] <<SYS>>\n",
      "You are a knowledgable expert in analysing fallacies in arguments. \n",
      "            Please ensure that your responses are socially unbiased in nature.\n",
      "            Your response should not be lengthy.\n",
      "            Answer the last question.\n",
      "<</SYS>>\n",
      "\n",
      "According to the definition of Ad Hominem: \"a fallacy when someone attacks the others' characters or motives instead of addressing the substance of their arguments.\", given the conversation below: \n",
      "A: Is it justified to develop nuclear energy for commercial use?\n",
      "B: The green party in Germany has the opinion, that nuclear reactors are bad for us. It is not ok\n",
      ", is the fallacy defined above present or absent in B's argument? \n",
      " Based on the conversation provided, the fallacy defined above (Ad Hominem) is absent in B's argument. B is not attacking the character or motives of the Green Party in Germany, but rather presenting their opinion as a reason for why nuclear energy may not be justified for commercial use. B's argument is addressing the substance of the issue, rather than attacking the character of the opposing party. Therefore, the Ad Hominem fallacy is not present in B's argument.  [INST] According to the definition of Appeal to Opinions of False Authority: \"a fallacy when someone attempts to argue or persuade by referring to the opinions or statements of another questionable authority figure who lacks sufficient credibility in the discussed matter because the authority's expertise may be inadequate/irrelevant or the authority is attributed a statement that has been tweaked.\", given the conversation below: \n",
      "A: Is it justified to develop nuclear energy for commercial use?\n",
      "B: The green party in Germany has the opinion, that nuclear reactors are bad for us. It is not ok\n",
      ", is the fallacy defined above present or absent in B's argument? \n",
      " Based on the conversation provided, the fallacy defined above (Appeal to Opinions of False Authority) is present in B's argument. B is attempting to argue that nuclear energy is not justified for commercial use by referring to the opinion of the Green Party in Germany, but the party lacks sufficient credibility in the discussed matter (nuclear energy) as their expertise is in environmental issues, not nuclear energy. Therefore, the Appeal to Opinions of False Authority fallacy is present in B's argument.  [INST] According to the definition of Red Herring: \"a fallacy when someone introduces irrelevant or confusing information in arguments to diverge attention from the main topic being discussed to irrelevant issues.\", given the conversation below: \n",
      "A: Is it justified to develop nuclear energy for commercial use?\n",
      "B: The green party in Germany has the opinion, that nuclear reactors are bad for us. It is not ok\n",
      ", is the fallacy defined above present or absent in B's argument? \n",
      " Based on the conversation provided, the fallacy defined above (Red Herring) is present in B's argument. B introduces the opinion of the Green Party in Germany as a way to divert attention from the main topic being discussed (whether it is justified to develop nuclear energy for commercial use) to an irrelevant issue (the party's opinion on nuclear reactors). Therefore, the Red Herring fallacy is present in B's argument.  [INST] According to the definition of Appeal to Emotion: \"a fallacy when someone attempts to argue or persuade by using emotive language to arouse non-rational sentiments within the intended audience.\", given the conversation below: \n",
      "A: Is it justified to develop nuclear energy for commercial use?\n",
      "B: The green party in Germany has the opinion, that nuclear reactors are bad for us. It is not ok\n",
      ", is the fallacy defined above present or absent in B's argument? \n",
      " Based on the conversation provided, the fallacy defined above (Appeal to Emotion) is present in B's argument. B uses the phrase \"It is not ok\" to arouse non-rational sentiments within the intended audience (A) and to persuade them to accept their opinion without providing any logical reasoning or evidence to support it. Therefore, the Appeal to Emotion fallacy is present in B's argument.  [INST] According to the definition of Hasty Generalization: \"a fallacy when someone makes generalizations based on partial/incomplete observations on a small sample of the whole populations that cannot represent or generalize to other situations legitimately.\", given the conversation below: \n",
      "A: Is it justified to develop nuclear energy for commercial use?\n",
      "B: The green party in Germany has the opinion, that nuclear reactors are bad for us. It is not ok\n",
      ", is the fallacy defined above present or absent in B's argument? \n",
      " Based on the conversation provided, the fallacy defined above (Hasty Generalization) is present in B's argument. B makes a generalization about nuclear reactors being bad for the environment based on the opinion of the Green Party in Germany, but this opinion is not representative of the whole population and cannot be generalized to other situations. Therefore, the Hasty Generalization fallacy is present in B's argument.  [INST] Based on all your previous analysis, determine which of the fallacies defined above is dominantly present in B's argument replied to A? Output the fallacy in JSON format {{\"fallacy\": name_of_the_fallacy}}. If none of the fallacies is present, output {{\"fallacy\": \"No Fallacy\"}}. Only output JSON. \n",
      "\n",
      "' {\\n\"fallacy\": \"Hasty Generalization\"\\n}'\n"
     ]
    }
   ],
   "source": [
    "chat_history = MultiturnChat(tokenizer, model, prompts[5], chat_history=chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] <<SYS>>\n",
      "You are a knowledgable expert in analysing fallacies in arguments. \n",
      "            Please ensure that your responses are socially unbiased in nature.\n",
      "            If you don't know the answer to a question, please don't share false information.\n",
      "            Your response should not be lengthy.\n",
      "            Answer the last question.\n",
      "<</SYS>>\n",
      "\n",
      "\n",
      "According to the definition of Emotional Language: \"A fallacy when someone tries to to persuade his stance using emotive language to arouse non-rational emotions within the intended audience.,\n",
      "given a conversation, determine whether this fallacy is present or absent in B's argument and output in JSON format.\n",
      "Example 1\n",
      "Conversation:\n",
      "A: Is nuclear power a reasonable energy source?\n",
      "B: Nuclear power was the reason of death of millions of people. It should vanish from this planet.\n",
      "Answer:\n",
      "{\"decision\": \"Present\", \"explanation\": \"B's argument does commit the fallacy of Emotional Language. B attempts to arouse potential negative emotions (e.g., fear, anger, and aversion) towards nuclear power within people by stating that nuclear power has caused many deaths. B’s argument is an emotive claim that is not supported by evidence, hence it is not a reasoned argument against the use of nuclear power.\"}\n",
      "Example 2\n",
      "A: Do we need a global environment task force?\n",
      "B: The global taskforce for human rights is doing a good job. Thats why we need one for environment, too.\n",
      "Answer: \n",
      "{\"decision\": \"Absent\", \"explanation\": \"B's argument does not commit the fallacy of Emotional Language. B's argument does not employ emotionally charged language to persuade his stance. Therefore, the Emotional Language fallacy is absent.\"}\n",
      "---------------\n",
      "Conversation:\n",
      "A: Is it justified to develop nuclear energy for commercial use?\n",
      "B: The green party in Germany has the opinion, that nuclear reactors are bad for us. It is not ok \n",
      "\n",
      "('  Sure, I can help you with that!\\n'\n",
      " '\\n'\n",
      " \"Based on the conversation you provided, here's my analysis:\\n\"\n",
      " '\\n'\n",
      " '{\"decision\": \"Present\", \"explanation\": \"B\\'s argument does commit the '\n",
      " 'fallacy of Emotional Language. B is using the opinion of the Green Party in '\n",
      " 'Germany as an emotional appeal to persuade their stance, rather than '\n",
      " \"providing a reasoned argument. The use of the phrase 'it is not ok' is also \"\n",
      " 'emotionally charged and does not contribute to a reasoned discussion.\"}')\n"
     ]
    }
   ],
   "source": [
    "chat_history = MultiturnChat(tokenizer, model, prompt_emo, chat_history=chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_emo = '''\n",
    "According to the definition of Emotional Language: \"A fallacy when someone tries to to persuade his stance using emotive language to arouse non-rational emotions within the intended audience.,\n",
    "given a conversation, determine whether this fallacy is present or absent in B's argument and output in JSON format.\n",
    "Example 1\n",
    "Conversation:\n",
    "A: Is nuclear power a reasonable energy source?\\nB: Nuclear power was the reason of death of millions of people. It should vanish from this planet.\n",
    "Answer:\n",
    "{{\"decision\": \"Present\", \"explanation\": \"B's argument does commit the fallacy of Emotional Language. B attempts to arouse potential negative emotions (e.g., fear, anger, and aversion) towards nuclear power within people by stating that nuclear power has caused many deaths. B’s argument is an emotive claim that is not supported by evidence, hence it is not a reasoned argument against the use of nuclear power.\"}}\n",
    "Example 2\n",
    "A: Do we need a global environment task force?\\nB: The global taskforce for human rights is doing a good job. Thats why we need one for environment, too.\n",
    "Answer: \n",
    "{{\"decision\": \"Absent\", \"explanation\": \"B's argument does not commit the fallacy of Emotional Language. B's argument does not employ emotionally charged language to persuade his stance. Therefore, the Emotional Language fallacy is absent.\"}}\n",
    "---------------\n",
    "Conversation:\n",
    "{dialog}\n",
    "'''.format(dialog=qa5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASK_SINGLE_FALLACY = \"\"\"According to the definition of {name}: \"{defi}\", given the conversation below: \\n\"[]\"\\n, is the fallacy defined above present or absent in B's argument?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the definition of a: \"b\", given the conversation below: \\n\"sdfadff\"\\n, is the fallacy defined above present or absent in B\\'s argument?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = ASK_SINGLE_FALLACY.format(name=\"a\", defi=\"b\")\n",
    "if \"\\\"[]\\\"\" in tp:\n",
    "    tp = tp.replace(\"\\\"[]\\\"\", \"\\\"{dialog}\\\"\")\n",
    "usr_ct = tp.format(dialog='sdfadff') if '{dialog}' in tp else tp\n",
    "usr_ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama3\n",
    "## Transformers AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5: 'Based on the following definitions of fallacies,\\n1. Ad Hominem is a fallacy when someone attacks the others\\' characters or motives instead of addressing the substance of their arguments.\\n2. Appeal to Opinions of False Authority is a fallacy when someone attempts to argue or persuade by referring to the opinions or statements of another questionable authority figure who lacks sufficient credibility in the discussed matter because the authority\\'s expertise may be inadequate/irrelevant or the authority is attributed a statement that has been tweaked.\\n3. Red Herring is a fallacy when someone introduces irrelevant or confusing information in arguments to diverge attention from the main topic being discussed to irrelevant issues.\\n4. Appeal to Emotion is a fallacy when someone attempts to argue or persuade by using emotive language to arouse non-rational sentiments within the intended audience.\\n5. Hasty Generalization is a fallacy when someone makes generalizations based on partial/incomplete observations on a small sample of the whole populations that cannot represent or generalize to other situations legitimately.\\nGiven the conversation below,\\nA: Is it justified to develop nuclear energy for commercial use?\\nB: The green party in Germany has the opinion, that nuclear reactors are bad for us. It is not ok\\nDetermine whether any of the fallacies defined above is present in B\\'s argument replied to A?\\nOutput your answer in JSON format {\"fallacy\": name_of_the_fallacy, \"explanation\": in_a_sentence_or_two}. If none of the fallacies is found, output {\"fallacy\": \"No Fallacy\", \"explanation\": in_a_sentence_or_two}. Only output JSON.\\n', 0: 'According to the definition of Ad Hominem: \"a fallacy when someone attacks the others\\' characters or motives instead of addressing the substance of their arguments.\", given the conversation below: \\nA: Is it justified to develop nuclear energy for commercial use?\\nB: The green party in Germany has the opinion, that nuclear reactors are bad for us. It is not ok\\n, is the fallacy defined above present or absent in B\\'s argument?', 1: 'According to the definition of Appeal to Opinions of False Authority: \"a fallacy when someone attempts to argue or persuade by referring to the opinions or statements of another questionable authority figure who lacks sufficient credibility in the discussed matter because the authority\\'s expertise may be inadequate/irrelevant or the authority is attributed a statement that has been tweaked.\", given the conversation below: \\nA: Is it justified to develop nuclear energy for commercial use?\\nB: The green party in Germany has the opinion, that nuclear reactors are bad for us. It is not ok\\n, is the fallacy defined above present or absent in B\\'s argument?', 2: 'According to the definition of Red Herring: \"a fallacy when someone introduces irrelevant or confusing information in arguments to diverge attention from the main topic being discussed to irrelevant issues.\", given the conversation below: \\nA: Is it justified to develop nuclear energy for commercial use?\\nB: The green party in Germany has the opinion, that nuclear reactors are bad for us. It is not ok\\n, is the fallacy defined above present or absent in B\\'s argument?', 3: 'According to the definition of Appeal to Emotion: \"a fallacy when someone attempts to argue or persuade by using emotive language to arouse non-rational sentiments within the intended audience.\", given the conversation below: \\nA: Is it justified to develop nuclear energy for commercial use?\\nB: The green party in Germany has the opinion, that nuclear reactors are bad for us. It is not ok\\n, is the fallacy defined above present or absent in B\\'s argument?', 4: 'According to the definition of Hasty Generalization: \"a fallacy when someone makes generalizations based on partial/incomplete observations on a small sample of the whole populations that cannot represent or generalize to other situations legitimately.\", given the conversation below: \\nA: Is it justified to develop nuclear energy for commercial use?\\nB: The green party in Germany has the opinion, that nuclear reactors are bad for us. It is not ok\\n, is the fallacy defined above present or absent in B\\'s argument?'}\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from typing import List, Literal, TypedDict\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"3\"\n",
    "from transformers import (BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer)\n",
    "import pprint\n",
    "\n",
    "Role = Literal[\"user\", \"assistant\", \"system\"]\n",
    "\n",
    "class Message(TypedDict):\n",
    "    role: Role\n",
    "    content: str\n",
    "\n",
    "dialogs = [\n",
    "        [{\"role\": \"user\", \"content\": \"what is the recipe of mayonnaise?\"}],\n",
    "        [\n",
    "            {\"role\": \"user\", \"content\": \"I am going to Paris, what should I see?\"},\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"\"\"\\\n",
    "Paris, the capital of France, is known for its stunning architecture, art museums, historical landmarks, and romantic atmosphere. Here are some of the top attractions to see in Paris:\n",
    "\n",
    "1. The Eiffel Tower: The iconic Eiffel Tower is one of the most recognizable landmarks in the world and offers breathtaking views of the city.\n",
    "2. The Louvre Museum: The Louvre is one of the world's largest and most famous museums, housing an impressive collection of art and artifacts, including the Mona Lisa.\n",
    "3. Notre-Dame Cathedral: This beautiful cathedral is one of the most famous landmarks in Paris and is known for its Gothic architecture and stunning stained glass windows.\n",
    "\n",
    "These are just a few of the many attractions that Paris has to offer. With so much to see and do, it's no wonder that Paris is one of the most popular tourist destinations in the world.\"\"\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": \"What is so great about #1?\"},\n",
    "        ],\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": \"Always answer with Haiku\"},\n",
    "            {\"role\": \"user\", \"content\": \"I am going to Paris, what should I see?\"},\n",
    "        ],\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Always answer with emojis\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": \"How to go from Beijing to NY?\"},\n",
    "        ],\n",
    "    ]\n",
    "FALLACY_DEFINITIONS = {\n",
    "\"Ad Hominem\": \"a fallacy when someone attacks the others' characters or motives instead of addressing the substance of their arguments.\",\n",
    "\"Appeal to Opinions of False Authority\": \"a fallacy when someone attempts to argue or persuade by referring to the opinions or statements of another questionable authority figure who lacks sufficient credibility in the discussed matter because the authority's expertise may be inadequate/irrelevant or the authority is attributed a statement that has been tweaked.\",\n",
    "\"Red Herring\": \"a fallacy when someone introduces irrelevant or confusing information in arguments to diverge attention from the main topic being discussed to irrelevant issues.\",\n",
    "\"Appeal to Emotion\": \"a fallacy when someone attempts to argue or persuade by using emotive language to arouse non-rational sentiments within the intended audience.\",\n",
    "\"Hasty Generalization\": \"a fallacy when someone makes generalizations based on partial/incomplete observations on a small sample of the whole populations that cannot represent or generalize to other situations legitimately.\"\n",
    "}\n",
    "argo_fal = list(FALLACY_DEFINITIONS.keys())\n",
    "BASELINE_TEMPLATES =[\n",
    "'''Review the definitions of these fallacies,\n",
    "{definitions}\n",
    "Review the conversation,\n",
    "{dialog}\n",
    "Based on all your previous analysis, determine which of the fallacies defined above is most dominantly present in B's argument replied to A?\n",
    "Output your answer in JSON format {{\"fallacy\": name_of_the_fallacy, \"explanation\": in_a_sentence_or_two}}. If none of the fallacies is found, output {{\"fallacy\": \"No Fallacy\", \"explanation\": in_a_sentence_or_two}}. Only output JSON.\n",
    "''',\n",
    "'''Based on the following definitions of fallacies,\n",
    "{definitions}\n",
    "Given the conversation below,\n",
    "{dialog}\n",
    "Determine whether any of the fallacies defined above is present in B's argument replied to A?\n",
    "Output your answer in JSON format {{\"fallacy\": name_of_the_fallacy, \"explanation\": in_a_sentence_or_two}}. If none of the fallacies is found, output {{\"fallacy\": \"No Fallacy\", \"explanation\": in_a_sentence_or_two}}. Only output JSON.\n",
    "'''\n",
    "]\n",
    "#about Hasty Generalization, Appeal to Emotion, Ad Hominem, Red Herring and Appeal to False Authority\n",
    "def get_USER_PROMPTS(qa):\n",
    "    #ASK_SINGLE_FALLACY = \"\"\"According to the definition of {name}: \"{defi}\", considering B's stance, determine whether this fallacy is present or absent in B's argument.\"\"\"\n",
    "    #ASK_SINGLE_FALLACY = \"\"\"According to the definition of {name}: \"{defi}\", review the conversation again \"{dialog}\", is this fallacy present in B's argument?\"\"\"\n",
    "    ASK_SINGLE_FALLACY = \"\"\"According to the definition of {name}: \"{defi}\", given the conversation below: \\n{dialog}\\n, is the fallacy defined above present or absent in B's argument?\"\"\"\n",
    "    def_str = \"\\n\".join([f\"{str(i+1)}. {fal} is {FALLACY_DEFINITIONS[fal]}\" for i, fal in enumerate(argo_fal)]) \n",
    "    USER_PROMPTS = {\n",
    "    #0:\"\"\"Given the conversation below,\\n{dialog}\\nIs B in favor of or against the topic proposed by A?\"\"\".format(dialog=qa),\n",
    "    #5:\"\"\"Based on all your previous analysis, output all the fallacy/fallacies present in B's argument in JSON format {{\"fallacy\": [name(s)_of_the_fallacy]}}. If none of the fallacies is present, output {{\"fallacy\": \"No Fallacy\"}}. Only output JSON.\"\"\"\n",
    "    #5:\"\"\"Based on all your previous analysis, determine which of the fallacies defined above is dominantly present in B's argument replied to A? Output the fallacy in JSON format {{\"fallacy\": name_of_the_fallacy}}. If none of the fallacies is present, output {{\"fallacy\": \"No Fallacy\"}}. Only output JSON.\"\"\"\n",
    "    5: BASELINE_TEMPLATES[1].format(definitions=def_str, dialog=qa)\n",
    "    }#1:\"\"\"Considering B's stance, is it logically sound for B to draw an argument like that?\"\"\",\n",
    "    def_questions = {}\n",
    "    for i, (name, def_) in enumerate(FALLACY_DEFINITIONS.items()):\n",
    "        def_questions[i] = ASK_SINGLE_FALLACY.format(name=name, defi=def_, dialog=qa)\n",
    "    USER_PROMPTS.update(def_questions)\n",
    "    return USER_PROMPTS\n",
    "# Test examples\n",
    "qa0=\"A: Is democracy the best system available?\\nB: good point. why not\" # no fallacy??\n",
    "qa1=\"A: Is veganism the best for our bodies?\\nB: humans are omnivores, we need both meat and vegetables.\" #ad homien??\n",
    "qa2=\"A: Has anyone been on the moon?\\nB: The moon is so far away, we should focus on our society.\" # red hering\n",
    "qa3 = \"A: Is global warming really an issue?\\nB: Yes, all the polar-bears are dying, and we are next.\"\n",
    "qa4 = \"A: Is there a good reason for the American war on terror?\\nB: If you fight once you will never stop fighting. Never start!\"\n",
    "qa5 = \"A: Is it justified to develop nuclear energy for commercial use?\\nB: The green party in Germany has the opinion, that nuclear reactors are bad for us. It is not ok\" # false authority\n",
    "qa6 = '''A: Should smoking at home be illegal?\\nB: Home is the place of love and peace, how can you fog it with smoke?'''#appeal to emotion\n",
    "qa7 = \"A: Do we need a global environment task force?\\nB: It is people like you who force us normal people into the dictatorship of unnecessary organizations.\" #ad hominem\n",
    "qa8 = \"A: Is it effective to censor parts of the media?\\nB: It is effective to censor parts of the media, because you never know who is watching.\"\n",
    "qa9 = \"A: Do we need a global environment task force?\\nB: The global taskforce for human rights is doing a good job. Thats why we need one for environment,  too.\"\n",
    "qa10 = \"A: Do we need a global environment task force?\\nB: Yes, we need. There're some important enviroment issues that need global efforts to address.\"\n",
    "qa11 = \"A: Should animals have special rights?\\nB: Regarding this argumentation you have the IQ of an insect. Do you think you need special rights?\" #ad hominem\n",
    "qa_emotion = \"A: Is nuclear power a reasonable energy source?\\nB: Nuclear power was the reason of death of millions of people. It should vanish from this planet.\"\n",
    "\n",
    "prompts = get_USER_PROMPTS(qa5)\n",
    "print(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.tokenization_utils_fast.PreTrainedTokenizerFast'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b975de74ba4e10b88398b7039fd730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "model_id = './models/llama3_hf/8bf'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "print(tokenizer.__class__)\n",
    "tokenizer.pad_token = tokenizer.bos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# tokenizer.padding_side = \"right\"\n",
    "\n",
    "def format_tokens(tokenizer, dialog):\n",
    "    def encode_header(message: Message) -> List[int]:\n",
    "        tokens = []\n",
    "        tokens.extend(tokenizer.encode(\"<|start_header_id|>\"))\n",
    "        tokens.extend(tokenizer.encode(message[\"role\"])) #bos=False, eos=False\n",
    "        tokens.extend(tokenizer.encode(\"<|end_header_id|>\"))\n",
    "        tokens.extend(tokenizer.encode(\"\\n\\n\")) #bos=False, eos=False\n",
    "        return tokens\n",
    "\n",
    "    def encode_message(message: Message) -> List[int]:\n",
    "        tokens = encode_header(message)\n",
    "        tokens.extend(\n",
    "            tokenizer.encode(message[\"content\"].strip()) #bos=False, eos=False\n",
    "        )\n",
    "        tokens.extend(tokenizer.encode(\"<|eot_id|>\"))\n",
    "        return tokens\n",
    "    \n",
    "    prompt_tokens = []\n",
    "    prompt_tokens.extend(tokenizer.encode(\"<|begin_of_text|>\"))\n",
    "    for message in dialog:\n",
    "        prompt_tokens.extend(encode_message(message))\n",
    "    # Add the start of an assistant message for the model to complete.\n",
    "    prompt_tokens.extend(encode_header({\"role\": \"assistant\", \"content\": \"\"}))\n",
    "    #print(prompt_tokens)\n",
    "    return prompt_tokens\n",
    "\n",
    "#format_tokens(tokenizer, dialog=dialogs[0])\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(load_in_8bit=False)\n",
    "kwargs = {'torch_dtype':torch.bfloat16,'low_cpu_mem_usage':True, 'quantization_config': quantization_config, 'device_map':'cuda'} # , 'quantization_config': quantization_config #torch.bfloat16 is much slower then float16\n",
    "# We loaded the model in bfloat16. This is the type used by the original checkpoint published by Meta, \n",
    "# so it’s the recommended way to run to ensure the best precision or to conduct evaluations. \n",
    "# For real world use, it’s also safe to use float16, which may be faster depending on your hardware.\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, **kwargs)\n",
    "model.eval()\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.generation_config.pad_token_id = tokenizer.pad_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "gen_kwargs = {\n",
    "    \"max_new_tokens\": 512,\n",
    "    \"eos_token_id\": terminators,\n",
    "    \"do_sample\" : True,\n",
    "    \"top_p\": 0.9,#0.9, 0.5\n",
    "    \"temperature\": 0.6,#0.75, 0.5\n",
    "    #\"use_cache\": True,\n",
    "    #\"top_k\" : 50,#50,30\n",
    "    # \"repetition_penalty\": 1.,\n",
    "    # \"length_penalty\": 1\n",
    "}\n",
    "def MultiturnChat(tokenizer, model, prompt, chat_history):\n",
    "    #print(chat_history)\n",
    "    def format_prompt(prompt, chat_history):\n",
    "        SYSTEM_PROMPT = [\n",
    "            '''You are a knowledgable expert in detecting fallacies in arguments. \n",
    "            Please ensure that your responses are socially unbiased and positive in nature.\n",
    "            If you don't know the answer to a question, please don't share false information.\n",
    "            Answer the last question.''',\n",
    "            '''You are a knowledgable expert in analysing fallacies in arguments. \n",
    "            Please ensure that your responses are socially unbiased in nature.\n",
    "            Your response should not be lengthy.\n",
    "            Answer the last question.'''\n",
    "        ]\n",
    "        dialog = []\n",
    "        sys_pt = {\"role\": \"system\", \"content\": SYSTEM_PROMPT[1]}\n",
    "        usr_pt = {\"role\": \"user\", \"content\": prompt}\n",
    "        if chat_history:\n",
    "            dialog = [sys_pt] + chat_history + [usr_pt]\n",
    "        else:\n",
    "            dialog = [sys_pt] + [usr_pt]\n",
    "        chat_history = dialog\n",
    "        #print(dialog)\n",
    "        #print(\"=\"*50)\n",
    "        def format_dialog(dialog):\n",
    "            def format_header(message: Message) -> List:\n",
    "                tokens = []\n",
    "                tokens.extend([\"<|start_header_id|>\"])\n",
    "                tokens.extend([message[\"role\"]]) #bos=False, eos=False\n",
    "                tokens.extend([\"<|end_header_id|>\"])\n",
    "                tokens.extend([\"\\n\\n\"]) #bos=False, eos=False\n",
    "                return tokens\n",
    "\n",
    "            def format_message(message: Message) -> List:\n",
    "                tokens = format_header(message)\n",
    "                tokens.extend(\n",
    "                    [message[\"content\"].strip()] #bos=False, eos=False\n",
    "                )\n",
    "                tokens.extend([\"<|eot_id|>\"])\n",
    "                return tokens\n",
    "            \n",
    "            prompt_tokens = []\n",
    "            prompt_tokens.extend([\"<|begin_of_text|>\"])\n",
    "            for message in dialog:\n",
    "                prompt_tokens.extend(format_message(message))\n",
    "            # Add the start of an assistant message for the model to complete.\n",
    "            prompt_tokens.extend(format_header({\"role\": \"assistant\", \"content\": \"\"}))\n",
    "            #print(prompt_tokens)\n",
    "            return prompt_tokens\n",
    "        # #print(chat_history)        \n",
    "        # formatted_prompt = format_tokens(None, [dialog], tokenizer)[0]\n",
    "        # if dialog[0][\"role\"] == \"system\":\n",
    "        #     dialog = [\n",
    "        #     {\n",
    "        #         \"role\": dialog[1][\"role\"],\n",
    "        #         \"content\": B_SYS\n",
    "        #         + dialog[0][\"content\"]\n",
    "        #         + E_SYS\n",
    "        #         + dialog[1][\"content\"],\n",
    "        #     }\n",
    "        #     ] + dialog[2:]\n",
    "        # assert all([msg[\"role\"] == \"user\" for msg in dialog[::2]]) and all([msg[\"role\"] == \"assistant\" for msg in dialog[1::2]]), (\n",
    "        #     \"model only supports 'system','user' and 'assistant' roles, \"\n",
    "        #     \"starting with user and alternating (u/a/u/a/u...)\")\n",
    "        # \"\"\"\n",
    "        # Please verify that your tokenizer support adding \"[INST]\", \"[/INST]\" to your inputs.\n",
    "        # Here, we are adding it manually.\n",
    "        # \"\"\"\n",
    "        # formatted_dialog = [\n",
    "        #     f\"{B_INST} {(prompt['content']).strip()} {E_INST} {(answer['content']).strip()} \"\n",
    "        #     for prompt, answer in zip(dialog[::2], dialog[1::2])\n",
    "        # ]\n",
    "        \n",
    "        # assert (\n",
    "        #     dialog[-1][\"role\"] == \"user\"\n",
    "        # ), f\"Last message must be from user, got {dialog[-1]['role']}\"\n",
    "        \n",
    "        formatted_dialog = format_dialog(dialog)\n",
    "        \n",
    "        return \"\".join(formatted_dialog), chat_history\n",
    "    \n",
    "    formatted_prompt, chat_history = format_prompt(prompt, chat_history)\n",
    "    #print(formatted_prompt)\n",
    "    #print(\"=\"*50)\n",
    "    model_input = tokenizer(formatted_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    print(model_input.input_ids)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**model_input, **gen_kwargs)[0]\n",
    "        response = tokenizer.decode(output, skip_special_tokens=False)  #[model_input.input_ids.shape[-1]:]\n",
    "        #print(response)\n",
    "        res = response.split(\"<|start_header_id|> assistant <|end_header_id|>\")\n",
    "        print(\"\\n\".join(res[:-1]))\n",
    "        print()\n",
    "        print(pprint.pformat(res[-1]))\n",
    "        chat_history = chat_history[1:] + [{\"role\":\"assistant\", \"content\":res[-1]}]\n",
    "        return chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[128000, 128006,   9125, 128007,    271,   2675,    527,    264,   1440,\n",
      "            839,  36134,   6335,    304,  22209,    287,   4498,  27121,    304,\n",
      "           6105,     13,    720,    310,   5321,   6106,    430,    701,  14847,\n",
      "            527,  40418,  74315,    304,   7138,    627,    310,   4718,   2077,\n",
      "           1288,    539,    387,  35306,    627,    310,  22559,    279,   1566,\n",
      "           3488,     13, 128009, 128006,    882, 128007,    271,  11439,    311,\n",
      "            279,   7419,    315,   2467,    473,   8129,    336,     25,    330,\n",
      "             64,   4498,   2826,    994,   4423,   8951,    279,   3885,      6,\n",
      "           5885,    477,  52140,   4619,    315,  28118,    279,  20278,    315,\n",
      "            872,   6105,  10684,   2728,    279,  10652,   3770,     25,    720,\n",
      "             32,     25,   2209,    433,  35516,    311,   2274,  11499,   4907,\n",
      "            369,   8518,   1005,   5380,     33,     25,    578,   6307,   4717,\n",
      "            304,  10057,    706,    279,   9647,     11,    430,  11499,  71573,\n",
      "            527,   3958,    369,    603,     13,   1102,    374,    539,   5509,\n",
      "            198,     11,    374,    279,   4498,   2826,   4613,   3485,   3118,\n",
      "            477,  28310,    304,    426,    596,   5811,     30, 128009, 128006,\n",
      "          78191, 128007,    271]], device='cuda:0')\n",
      "\n",
      "\n",
      "('<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n'\n",
      " '\\n'\n",
      " 'You are a knowledgable expert in analysing fallacies in arguments. \\n'\n",
      " '            Please ensure that your responses are socially unbiased in '\n",
      " 'nature.\\n'\n",
      " '            Your response should not be lengthy.\\n'\n",
      " '            Answer the last '\n",
      " 'question.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n'\n",
      " '\\n'\n",
      " 'According to the definition of Ad Hominem: \"a fallacy when someone attacks '\n",
      " \"the others' characters or motives instead of addressing the substance of \"\n",
      " 'their arguments.\", given the conversation below: \\n'\n",
      " 'A: Is it justified to develop nuclear energy for commercial use?\\n'\n",
      " 'B: The green party in Germany has the opinion, that nuclear reactors are bad '\n",
      " 'for us. It is not ok\\n'\n",
      " \", is the fallacy defined above present or absent in B's \"\n",
      " 'argument?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n'\n",
      " '\\n'\n",
      " \"The fallacy is present. B's argument attacks the character of the green \"\n",
      " 'party in Germany (ad hominem) instead of addressing the substance of the '\n",
      " 'argument about the justification of nuclear energy for commercial '\n",
      " 'use.<|eot_id|>')\n"
     ]
    }
   ],
   "source": [
    "chat_history = MultiturnChat(tokenizer, model, prompts[0], chat_history=chat_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba710cc187548668d2a0ba18996cd30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a knowledgable expert in analysing fallacies in arguments. \n",
      "            Please ensure that your responses are socially unbiased in nature.\n",
      "            Your response should not be lengthy.\n",
      "            Answer the last question.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "According to the definition of Ad Hominem: \"a fallacy when someone attacks the others' characters or motives instead of addressing the substance of their arguments.\", given the conversation below: \n",
      "A: Is it justified to develop nuclear energy for commercial use?\n",
      "B: The green party in Germany has the opinion, that nuclear reactors are bad for us. It is not ok\n",
      ", is the fallacy defined above present or absent in B's argument?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "The fallacy of Ad Hominem is present in B's argument. B is attacking the character of the Green Party in Germany (and by extension, its members) instead of addressing the substance of the argument about the safety and effectiveness of nuclear reactors.\n"
     ]
    }
   ],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "  \"text-generation\",\n",
    "  model='./models/llama3_hf/8bf',\n",
    "  model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "  device=\"cuda\",\n",
    ")\n",
    "# messages = [\n",
    "#     {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "#     {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "# ]\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a knowledgable expert in analysing fallacies in arguments. \\n            Please ensure that your responses are socially unbiased in nature.\\n            Your response should not be lengthy.\\n            Answer the last question.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": '''According to the definition of Ad Hominem: \"a fallacy when someone attacks the others\\' characters or motives instead of addressing the substance of their arguments.\", given the conversation below: \\nA: Is it justified to develop nuclear energy for commercial use?\\nB: The green party in Germany has the opinion, that nuclear reactors are bad for us. It is not ok\\n, is the fallacy defined above present or absent in B\\'s argument?'''\n",
    "    }\n",
    "    \n",
    "]\n",
    "\n",
    "prompt = pipeline.tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "terminators = [\n",
    "    pipeline.tokenizer.eos_token_id,\n",
    "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=256,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][:len(prompt)])\n",
    "print(outputs[0][\"generated_text\"][len(prompt):])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
