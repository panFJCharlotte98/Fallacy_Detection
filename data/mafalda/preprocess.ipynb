{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: A total of 200 examples.\n",
      "{'ad hominem': 7,\n",
      " 'ad populum': 12,\n",
      " 'appeal to anger': 3,\n",
      " 'appeal to false authority': 6,\n",
      " 'appeal to fear': 5,\n",
      " 'appeal to nature': 9,\n",
      " 'appeal to positive emotion': 2,\n",
      " 'appeal to ridicule': 7,\n",
      " 'appeal to tradition': 3,\n",
      " 'appeal to worse problems': 5,\n",
      " 'causal oversimplification': 16,\n",
      " 'circular reasoning': 8,\n",
      " 'equivocation': 4,\n",
      " 'fallacy of division': 2,\n",
      " 'false analogy': 5,\n",
      " 'false causality': 12,\n",
      " 'false dilemma': 6,\n",
      " 'guilt by association': 3,\n",
      " 'hasty generalization': 20,\n",
      " 'no fallacy': 63,\n",
      " 'slippery slope': 9,\n",
      " 'straw man': 2,\n",
      " 'tu quoque': 3}\n",
      "{1: 190, 2: 8, 3: 2}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import json\n",
    "import regex\n",
    "import pprint\n",
    "def preprocess_mafalda(input_paths):\n",
    "    label_map = {\n",
    "        # Fallacy of Credibility\n",
    "        'ad hominem': 'ad hominem',\n",
    "        'tu quoque': 'tu quoque',\n",
    "        'guilt by association': 'guilt by association',\n",
    "        'ad populum': 'ad populum',\n",
    "        'appeal to nature': 'appeal to nature',\n",
    "        'appeal to tradition': 'appeal to tradition',\n",
    "        'appeal to (false) authority': 'appeal to false authority',\n",
    "        # Fallacy of Logic\n",
    "        'causal oversimplification': 'causal oversimplification',\n",
    "        'hasty generalization': 'hasty generalization',\n",
    "        'false causality': 'false causality',\n",
    "        'false analogy': 'false analogy',\n",
    "        'false dilemma': 'false dilemma',\n",
    "        'slippery slope': 'slippery slope',\n",
    "        'fallacy of division': 'fallacy of division',\n",
    "        'straw man': 'straw man',\n",
    "        'circular reasoning': 'circular reasoning',\n",
    "        'equivocation': 'equivocation',\n",
    "        # Fallacy of Emotion\n",
    "        'appeal to positive emotion': 'appeal to positive emotion',\n",
    "        'appeal to anger': 'appeal to anger',\n",
    "        'appeal to fear': 'appeal to fear',\n",
    "        'appeal to pity': 'appeal to pity',\n",
    "        'Appeal to Ridicule': 'appeal to ridicule',\n",
    "        'appeal to ridicule': 'appeal to ridicule',\n",
    "        'appeal to worse problems': 'appeal to worse problems',\n",
    "        # Others\n",
    "        'nothing': 'no fallacy',\n",
    "        'to clean': 'to be confirmed',\n",
    "    }\n",
    "    new_data = []\n",
    "    all_labels = []\n",
    "    label_counts = []\n",
    "    for input_path in input_paths:\n",
    "        for i, one_data in enumerate([json.loads(line) for line in open(input_path)]):\n",
    "            # label as dominant label\n",
    "            labels = [label_map[l[2]] for l in one_data['labels']]\n",
    "            if len(labels) == 0:\n",
    "                labels = ['no fallacy']\n",
    "            if len(labels) > 1:\n",
    "                labels = [l for l in labels if l != 'no fallacy']\n",
    "            segment_annotations = [{'segment':seg, 'labels':[l[0] for l in lb_ls]} for seg, lb_ls in json.loads(one_data['sentences_with_labels']).items()]\n",
    "\n",
    "            if len(labels) == 1:\n",
    "                other_labels = []\n",
    "            else:\n",
    "                # find the dominant label\n",
    "                label_count = {}\n",
    "                for item in segment_annotations:\n",
    "                    s, ls = item['segment'], item['labels']\n",
    "                    for l in ls:\n",
    "                        if l not in ['nothing', 'to clean']:\n",
    "                            if l not in label_count:\n",
    "                                label_count[l] = 1\n",
    "                            else:\n",
    "                                label_count[l] += 1\n",
    "                max_count = max(list(label_count.values()))\n",
    "                dominant_labels = [label_map[k] for k, v in label_count.items() if v == max_count] # most dominant \n",
    "                other_labels = list(set(labels) - set(dominant_labels))\n",
    "                labels = dominant_labels\n",
    "\n",
    "            if len(other_labels) == 0:\n",
    "                other_labels = [\"\"]\n",
    "            one_new_data = {\"id\": i+1, 'text': one_data['text'].replace(\"\\n\",\" \").strip(), 'label': labels, 'other_labels': other_labels,\n",
    "                            \"segment_annotation\": segment_annotations,\n",
    "                            \"comment\": [{'fallacy': cmt.split(\":\")[0].strip(), 'comment': \":\".join(cmt.split(\":\")[1:]).strip()}  for cmt in one_data['comments']]\n",
    "                        }\n",
    "            new_data.append(one_new_data)\n",
    "            all_labels.extend(labels)\n",
    "            label_counts.append(len(labels))\n",
    "\n",
    "    fal_list = list(set(all_labels))\n",
    "    fal_count = {}\n",
    "    for l in all_labels:\n",
    "        if l not in fal_count:\n",
    "            fal_count[l] = 1\n",
    "        else:\n",
    "            fal_count[l] += 1\n",
    "\n",
    "    label_counts_dist = {}\n",
    "    for c in label_counts:\n",
    "        if c not in label_counts_dist:\n",
    "            label_counts_dist[c] = 1\n",
    "        else:\n",
    "            label_counts_dist[c] += 1\n",
    "    \n",
    "    print(f\"Test: A total of {len(new_data)} examples.\")\n",
    "    print(pprint.pformat(fal_count))\n",
    "    print(pprint.pformat(label_counts_dist))\n",
    "    json.dump(new_data, open('test.json', 'w'), indent=4)\n",
    "    \n",
    "    return\n",
    "preprocess_mafalda(['./raw/gold_standard_dataset.jsonl'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
