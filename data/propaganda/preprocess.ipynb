{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 13 labels.\n",
      "{'Appeal to Fear': 0, 'Name-calling': 1, 'Straw Man': 2, 'Flag-Waving': 3, 'Whataboutism': 4, 'False Dilemma': 5, 'Red Herring': 6, 'Appeal to False Authority': 7, 'Causal Oversimplification': 8, 'Ad Populum': 9, 'Equivocation': 10, 'Reductio Ad Hitlerum': 11, 'Doubt Credibility': 12}\n",
      "train\n",
      "label_for_split\n",
      "1     717\n",
      "12    278\n",
      "0     128\n",
      "3     127\n",
      "8     114\n",
      "7      62\n",
      "5      57\n",
      "4      33\n",
      "11     30\n",
      "6      19\n",
      "9       7\n",
      "10      6\n",
      "2       6\n",
      "Name: count, dtype: int64\n",
      "dev\n",
      "label_for_split\n",
      "1     119\n",
      "12     46\n",
      "0      22\n",
      "3      21\n",
      "8      19\n",
      "5      10\n",
      "7      10\n",
      "4       6\n",
      "11      5\n",
      "6       3\n",
      "2       1\n",
      "9       1\n",
      "10      1\n",
      "Name: count, dtype: int64\n",
      "test\n",
      "{'Ad Populum': 1,\n",
      " 'Appeal to False Authority': 10,\n",
      " 'Appeal to Fear': 21,\n",
      " 'Causal Oversimplification': 19,\n",
      " 'Doubt Credibility': 47,\n",
      " 'Equivocation': 1,\n",
      " 'False Dilemma': 10,\n",
      " 'Flag-Waving': 21,\n",
      " 'Name-calling': 120,\n",
      " 'Red Herring': 3,\n",
      " 'Reductio Ad Hitlerum': 5,\n",
      " 'Straw Man': 2,\n",
      " 'Whataboutism': 5}\n",
      "total = 2113; train=1583; dev=265; test=265\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pprint\n",
    "\n",
    "def preprocess_propaganda(article_folder, label_folder, reduce_redundant=True):\n",
    "    articles = {int(f.split(\".\")[0].split(\"article\")[-1]): join(article_folder, f) for f in listdir(article_folder) if isfile(join(article_folder, f)) and f.endswith('txt')}\n",
    "    labels = {int(f.split(\".\")[0].split(\"article\")[-1]): join(label_folder, f) for f in listdir(label_folder) if isfile(join(label_folder, f))}\n",
    "    articles = dict(sorted(articles.items()))\n",
    "    labels = dict(sorted(labels.items()))\n",
    "    assert len(articles) == len(labels)\n",
    "    # label_dict = {\n",
    "    #     'Loaded_Language': 'Loaded Language',\n",
    "    #     'Name_Calling,Labeling': 'Name Calling or Labeling',\n",
    "    #     'Exaggeration,Minimisation': 'Exaggeration or Minimisation',\n",
    "    #     'Doubt': \"Attack Credibility (Doubt)\", #Questioning the credibility of someone or something.\n",
    "    #     'Appeal_to_fear-prejudice': 'Appeal to Fear or Prejudice',\n",
    "    #     'Flag-Waving': 'Flag-Waving',\n",
    "    #     'Causal_Oversimplification': 'Causal Oversimplification',\n",
    "    #     'AppealtoAuthority': 'Appeal to False Authority', \n",
    "    #     'Appeal_to_Authority': 'Appeal to False Authority',\n",
    "    #     'Black-and-White_Fallacy': 'False Dilemma (Black-and-White Fallacy)',\n",
    "    #     'Thought-terminating_Cliches': 'Thought-terminating Cliches',\n",
    "    #     'Whataboutism': 'Whataboutism',\n",
    "    #     'Reductio_ad_hitlerum': 'Reductio Ad Hitlerum',\n",
    "    #     'Red_Herring': 'Red Herring',\n",
    "    #     'Straw_Men': 'Straw Man',\n",
    "    #     'Slogans': 'Slogans', \n",
    "    #     'Repetition': 'Repetition',\n",
    "    #     'Bandwagon': 'Ad Populum (Bandwagon Fallacy)',\n",
    "    #     'Obfuscation,Intentional_Vagueness,Confusion': 'Obfuscation,Intentional_Vagueness,Confusion', #OIVC\n",
    "    # }\n",
    "    label_dict = {\n",
    "        'Name_Calling,Labeling': 'Name-calling',\n",
    "        'Doubt': \"Doubt Credibility\", #Questioning the credibility of someone or something.\n",
    "        'Appeal_to_fear-prejudice': 'Appeal to Fear',\n",
    "        'Flag-Waving': 'Flag-Waving',\n",
    "        'Causal_Oversimplification': 'Causal Oversimplification',\n",
    "        'AppealtoAuthority': 'Appeal to False Authority', \n",
    "        'Appeal_to_Authority': 'Appeal to False Authority',\n",
    "        'Black-and-White_Fallacy': 'False Dilemma',\n",
    "        'Whataboutism': 'Whataboutism',\n",
    "        'Reductio_ad_hitlerum': 'Reductio Ad Hitlerum',\n",
    "        'Red_Herring': 'Red Herring',\n",
    "        'Straw_Men': 'Straw Man',\n",
    "        'Bandwagon': 'Ad Populum',\n",
    "        'Obfuscation,Intentional_Vagueness,Confusion': 'Equivocation', #OIVC\n",
    "    }\n",
    "    label_space = list(set(list(label_dict.values())))\n",
    "    label_ids = list(range(len(label_space)))\n",
    "    label_id_map = dict(zip(label_space, label_ids))\n",
    "    print(f\"A total of {len(label_space)} labels.\")\n",
    "    print(label_id_map)\n",
    "    id_label_map = {v:k for k, v in label_id_map.items()}\n",
    "    examples= []\n",
    "    \n",
    "    df_recs = []\n",
    "    appeared_fal_spans = []\n",
    "    for aid, article_pth in articles.items():\n",
    "        label_pth = labels[aid]\n",
    "        # print(article_pth)\n",
    "        # print(label_pth)\n",
    "        sentences = [t for t in open(article_pth, 'r').readlines() if t!=\"\\n\"] # read lines into a list\n",
    "        title = \" \".join(sentences[0].strip().split()).replace(\"\\u2019\", \"'\").encode('ascii', errors='ignore').strip().decode('ascii')\n",
    "        sentences = sentences[1:]\n",
    "        article_text = open(article_pth).read()\n",
    "        appeared = []\n",
    "        for line in open(label_pth, 'r'):\n",
    "            _, techs, start, end = line.split()\n",
    "            #gold_ls = list(set([label_dict[g] for g in techs.split(',')]))\n",
    "            if techs in ['AppealtoAuthority', 'AppealtoEmotion','AdHominem','Slipperyslope', 'FalseCause']:\n",
    "                print(label_pth)\n",
    "            if techs in label_dict:  \n",
    "                gold_ls = [label_dict[techs]]\n",
    "                start = int(start)\n",
    "                end = int(end)\n",
    "                fal_span_ori = article_text[start:(end+1)]\n",
    "                fal_span = fal_span_ori.strip()\n",
    "                start = start + fal_span_ori.find(fal_span)\n",
    "                end = start + len(fal_span) - 1\n",
    "                for i, s in enumerate(sentences): \n",
    "                    start_idx = article_text.find(s) \n",
    "                    end_idx = start_idx + len(s) - 1\n",
    "                    if (fal_span.strip() in s) and (fal_span not in appeared) and (start >= start_idx) and (end <= end_idx):\n",
    "                        appeared.append(fal_span)\n",
    "                        pre_t, post_t = [], []\n",
    "                        if i == 2:\n",
    "                            pre_t.append(sentences[i-1])\n",
    "                        elif i > 2:\n",
    "                            pre_t.extend([sentences[i-2], sentences[i-1]])\n",
    "                        if i == (len(sentences)-2):\n",
    "                            post_t.append(sentences[i+1])\n",
    "                        elif i < (len(sentences)-2):\n",
    "                            post_t.extend([sentences[i+1], sentences[i+2]])\n",
    "                        pre_t = [\" \".join(t.split()).replace(\"\\u2019\", \"'\").encode('ascii', errors='ignore').strip().decode('ascii') for t in pre_t]\n",
    "                        post_t = [\" \".join(t.split()).replace(\"\\u2019\", \"'\").encode('ascii', errors='ignore').strip().decode('ascii') for t in post_t]\n",
    "                        \n",
    "                        fal_span = \" \".join(fal_span.split()).replace(\"\\u2019\", \"'\").encode('ascii', errors='ignore').strip().decode('ascii')\n",
    "                        if len(fal_span.split()[-1]) == 1: #strip out the single letter\n",
    "                            fal_span = \" \".join(fal_span.split()[:-1])\n",
    "                        fal_t = \" \".join(s.split()).replace(\"\\u2019\", \"'\").encode('ascii', errors='ignore').strip().decode('ascii')\n",
    "                        assert fal_span in fal_t\n",
    "                        fal_t = fal_t.replace(fal_span, '<'+fal_span+'>') # 0416 added\n",
    "                        if reduce_redundant:\n",
    "                            if fal_span not in appeared_fal_spans:\n",
    "                                appeared_fal_spans.append(fal_span)\n",
    "                                one_example = {\n",
    "                                    \"id\": len(examples),\n",
    "                                    \"title\": title,\n",
    "                                    \"pre_text\": pre_t,\n",
    "                                    \"fal_span\": fal_span,\n",
    "                                    \"text\": fal_t,\n",
    "                                    \"post_text\": post_t,\n",
    "                                    \"label\": gold_ls,\n",
    "                                }\n",
    "                                df_recs.append((one_example['id'], one_example['title'], label_id_map[gold_ls[0]]))\n",
    "                                examples.append(one_example)\n",
    "                        else:\n",
    "                            one_example = {\n",
    "                                \"id\": len(examples),\n",
    "                                \"title\": title,\n",
    "                                \"pre_text\": pre_t,\n",
    "                                \"fal_span\": fal_span,\n",
    "                                \"text\": fal_t,\n",
    "                                \"post_text\": post_t,\n",
    "                                \"label\": gold_ls,\n",
    "                            }\n",
    "                            df_recs.append((one_example['id'], one_example['title'], label_id_map[gold_ls[0]]))\n",
    "                            examples.append(one_example)\n",
    "                        break\n",
    "            #     break\n",
    "            # break\n",
    "\n",
    "    df = pd.DataFrame(df_recs, columns=['eid','title', 'label_for_split'])\n",
    "    skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "    for train_ids, test_dev_ids in skf.split(np.zeros(len(df.index)), df['label_for_split']):\n",
    "        print(\"train\")\n",
    "        print(df.iloc[train_ids]['label_for_split'].value_counts())\n",
    "        train_ids = df.iloc[train_ids]['eid'].tolist()\n",
    "        df_test_dev = df.iloc[test_dev_ids].reset_index(drop=True)\n",
    "        break\n",
    "    skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "    for dev_ids, test_ids in skf.split(np.zeros(len(df_test_dev.index)), df_test_dev['label_for_split']):\n",
    "        print(\"dev\")\n",
    "        print(df_test_dev.iloc[dev_ids]['label_for_split'].value_counts())\n",
    "        print(\"test\")\n",
    "        test_class_dist = {id_label_map[k]: v for k, v in dict(df_test_dev.iloc[test_ids]['label_for_split'].value_counts()).items()}\n",
    "        print(pprint.pformat(test_class_dist))\n",
    "        dev_ids = df_test_dev.iloc[dev_ids]['eid'].tolist()\n",
    "        test_ids = df_test_dev.iloc[test_ids]['eid'].tolist()\n",
    "        break\n",
    "    \n",
    "    assert len(train_ids) + len(dev_ids) + len(test_ids) == len(examples)\n",
    "    train, dev, test = [], [], []\n",
    "    is_found = False\n",
    "    for e in examples:\n",
    "        if e['id'] in train_ids:\n",
    "            ###################\n",
    "            if (not is_found) and (e['label'][0] == 'Ad Populum'):\n",
    "                dev.append(e)\n",
    "                is_found = True\n",
    "                continue\n",
    "            ###################\n",
    "            train.append(e)\n",
    "        elif e['id'] in dev_ids:\n",
    "            dev.append(e)\n",
    "        elif e['id'] in test_ids:\n",
    "            test.append(e)\n",
    "    print(f\"total = {len(examples)}; train={len(train)}; dev={len(dev)}; test={len(test)}\")\n",
    "    os.makedirs('./new_data', exist_ok=True)\n",
    "    for sp, name in zip([train, dev, test], ['train', 'dev', 'test']):\n",
    "        json.dump(sp, open(f'./new_data/{name}.json', 'w'), indent=4,)\n",
    "    return\n",
    "\n",
    "article_folder = \"./train-articles/\"\n",
    "label_folder = \"./train-labels-FLC/\"\n",
    "preprocess_propaganda(article_folder, label_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black-and-White Fallacy\n",
      "Causal Oversimplification\n",
      "Attack/Question Credibility\n",
      "Exaggeration or Minimisation\n",
      "Exaggeration or Minimisation\n",
      "Appeal to Fear or Prejudice\n",
      "Flag-Waving\n",
      "Appeal to False Authority\n",
      "Appeal to False Authority\n",
      "Loaded Language\n",
      "Name Calling or Labeling\n",
      "Name Calling or Labeling\n",
      "Red Herring\n",
      "Reductio Ad Hitlerum\n",
      "Slogans\n",
      "Straw Man\n",
      "Thought-terminating Cliches\n",
      "Whataboutism\n",
      "Appeal to Emotion\n",
      "Ad Hominem\n",
      "Slippery Slope\n",
      "False Causality\n",
      "Repetition\n",
      "Bandwagon\n",
      "Obfuscation\n",
      "Intentional Vagueness\n",
      "Confusion\n"
     ]
    }
   ],
   "source": [
    "label_dict = {\n",
    "    'Black-and-White_Fallacy': 'Black-and-White Fallacy',\n",
    "    'Causal_Oversimplification': 'Causal Oversimplification',\n",
    "    'Doubt': 'Attack/Question Credibility', #Questioning the credibility of someone or something.\n",
    "    'Exaggeration': 'Exaggeration or Minimisation',\n",
    "    'Minimisation': 'Exaggeration or Minimisation',\n",
    "    'Appeal_to_fear-prejudice': 'Appeal to Fear or Prejudice',\n",
    "    'Flag-Waving': 'Flag-Waving',\n",
    "    'AppealtoAuthority': 'Appeal to False Authority', \n",
    "    'Appeal_to_Authority': 'Appeal to False Authority', \n",
    "    'Loaded_Language': 'Loaded Language',\n",
    "    'Name_Calling': 'Name Calling or Labeling',\n",
    "    'Labeling': 'Name Calling or Labeling',\n",
    "    'Red_Herring': 'Red Herring',\n",
    "    'Reductio_ad_hitlerum': 'Reductio Ad Hitlerum',\n",
    "    'Slogans': 'Slogans', \n",
    "    'Straw_Men': 'Straw Man',\n",
    "    'Thought-terminating_Cliches': 'Thought-terminating Cliches',\n",
    "    'Whataboutism': 'Whataboutism',\n",
    "    'AppealtoEmotion': 'Appeal to Emotion', \n",
    "    'AdHominem': 'Ad Hominem', \n",
    "    'Slipperyslope': 'Slippery Slope', \n",
    "    'FalseCause': 'False Causality',\n",
    "    'Repetition': 'Repetition',\n",
    "    'Bandwagon': 'Bandwagon',\n",
    "    'Obfuscation': 'Obfuscation',\n",
    "    'Intentional_Vagueness': 'Intentional Vagueness',\n",
    "    'Confusion': 'Confusion',\n",
    "}\n",
    "\n",
    "for k, v in label_dict.items():\n",
    "    print(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
